{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99a43cd",
   "metadata": {},
   "source": [
    "### Modelos de Classifica√ß√£o vs. Modelos de Regress√£o\n",
    "\n",
    "Como j√° vimos, modelos de **Regress√£o Linear** s√£o excelentes para prever valores cont√≠nuos, como o pre√ßo de um im√≥vel ou a quantidade de vendas de um produto.\n",
    "\n",
    "Entretanto, em muitos cen√°rios, queremos prever uma categoria, n√£o um n√∫mero. Por exemplo:\n",
    "- Este e-mail √© *spam* ou *n√£o spam*?\n",
    "- Este cliente ir√° *cancelar* ou *n√£o cancelar* a assinatura?\n",
    "- O paciente est√° *doente* ou *saud√°vel*?\n",
    "\n",
    "Para esses casos, usamos os **Modelos de Classifica√ß√£o**. Eles nos ajudam a classificar uma observa√ß√£o em uma de duas ou mais categorias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed9db1",
   "metadata": {},
   "source": [
    "### O que √© a Regress√£o Log√≠stica?\n",
    "\n",
    "Apesar do nome \"Regress√£o\", a Regress√£o Log√≠stica √© um **modelo de classifica√ß√£o**. Ela √© o nosso ponto de partida por ser uma t√©cnica poderosa e fundamental.\n",
    "\n",
    "A ideia central √© modelar a **probabilidade** de uma observa√ß√£o pertencer a uma determinada classe. Por exemplo, a probabilidade de um e-mail ser spam, dado o seu conte√∫do.\n",
    "\n",
    "Para fazer isso, precisamos entender um conceito estat√≠stico chave: **Odds (Chance)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945de245",
   "metadata": {},
   "source": [
    "<img src=\"regressao_logistica.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f868c7b",
   "metadata": {},
   "source": [
    "## Passo 1: Entendendo o Conceito de Odds (Chance)\n",
    "\n",
    "Em estat√≠stica, **Odds** (ou **Chance**, em portugu√™s) √© uma forma de expressar a probabilidade. Ela representa a raz√£o entre a probabilidade de um evento acontecer (sucesso) e a probabilidade de ele n√£o acontecer (fracasso).\n",
    "\n",
    "A f√≥rmula √© bem simples:\n",
    "\n",
    "$$\\text{Odds} = \\frac{P}{1 - P}$$\n",
    "\n",
    "Onde \\( P \\) √© a probabilidade de sucesso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254013f",
   "metadata": {},
   "source": [
    "#### üí° Exemplo Pr√°tico (Matem√°tica Primeiro!)\n",
    "\n",
    "Vamos supor que a probabilidade de um aluno ser aprovado em um exame √© de 80% (ou \\( P = 0,8 \\)).\n",
    "\n",
    "Qual √© a chance (Odds) de ele ser aprovado?\n",
    "\n",
    "1.  **Probabilidade de sucesso (P)**: \\( 0,8 \\)\n",
    "2.  **Probabilidade de fracasso (1 - P)**: \\( 1 - 0,8 = 0,2 \\)\n",
    "\n",
    "Agora, aplicamos a f√≥rmula:\n",
    "\n",
    "$\\text{Odds de Aprova√ß√£o} = \\frac{0,8}{0,2} = 4$\n",
    "\n",
    "> **Interpreta√ß√£o:** A chance de um aluno ser aprovado √© de **4 para 1**. Ou seja, √© 4 vezes mais prov√°vel que ele seja aprovado do que n√£o seja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a587b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de sucesso √©: 0.8\n",
      "As Odds de sucesso s√£o: 4.0 para 1\n"
     ]
    }
   ],
   "source": [
    "# Agora, vamos replicar o c√°lculo com Python\n",
    "p_sucesso = 0.8\n",
    "\n",
    "# Calculando as Odds\n",
    "odds = p_sucesso / (1 - p_sucesso)\n",
    "\n",
    "print(f\"A probabilidade de sucesso √©: {p_sucesso}\")\n",
    "print(f\"As Odds de sucesso s√£o: {odds:.1f} para 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba2e3b",
   "metadata": {},
   "source": [
    "## Passo 2: A M√°gica do Logaritmo - O Log-Odds\n",
    "\n",
    "Voc√™ pode se perguntar: *\"Por que n√£o modelamos a probabilidade diretamente?\"*\n",
    "\n",
    "A resposta √© que a probabilidade √© restrita (entre 0 e 1), mas os modelos lineares (como a base da regress√£o log√≠stica) podem prever qualquer valor de -‚àû a +‚àû. Precisamos de uma forma de \"esticar\" a escala de probabilidade.\n",
    "\n",
    "√â aqui que entra o **logaritmo natural**! Ao aplicarmos o `log` nas Odds, criamos o **Log-Odds** (ou **Logit**).\n",
    "\n",
    "$$\\text{Log-Odds} = \\log(\\text{Odds}) = \\log\\left( \\frac{P}{1 - P} \\right)$$\n",
    "\n",
    "O Log-Odds transforma a escala de `(0, 1)` para `(-‚àû, +‚àû)`, que √© exatamente o que um modelo linear precisa!\n",
    "\n",
    "**A sacada da Regress√£o Log√≠stica √© modelar o Log-Odds como uma combina√ß√£o linear das nossas vari√°veis**, assim como na regress√£o linear simples!\n",
    "\n",
    "$$\\log\\left( \\frac{P}{1 - P} \\right) = z = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e2579",
   "metadata": {},
   "source": [
    "#### üí° Continuando nosso Exemplo\n",
    "\n",
    "J√° calculamos que as Odds de aprova√ß√£o s√£o 4. Agora, vamos calcular o Log-Odds.\n",
    "\n",
    "**Matematicamente:**\n",
    "$\\text{Log-Odds} = \\log(4) \\approx 1.386$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f835e45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O valor de Log-Odds (z) √©: 1.3863\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# O valor 'z' representa o resultado da equa√ß√£o linear (o Log-Odds)\n",
    "z = np.log(odds)\n",
    "\n",
    "print(f\"O valor de Log-Odds (z) √©: {z:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8ea1f",
   "metadata": {},
   "source": [
    "## Passo 3: Revertendo o Processo com a Fun√ß√£o Sigmoide\n",
    "\n",
    "√ìtimo! O modelo vai nos dar um valor `z` (o Log-Odds). Mas no final do dia, queremos uma **probabilidade** (algo entre 0 e 1), que √© muito mais f√°cil de interpretar.\n",
    "\n",
    "Para fazer o caminho de volta (de Log-Odds para Probabilidade), usamos a fun√ß√£o inversa, chamada de **Fun√ß√£o Sigmoide** (ou Fun√ß√£o Log√≠stica).\n",
    "\n",
    "$$P = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Essa fun√ß√£o \"espreme\" qualquer n√∫mero real (de -‚àû a +‚àû) para dentro do intervalo `(0, 1)`, resultando em uma curva em formato de \"S\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b0e19",
   "metadata": {},
   "source": [
    "#### üí° Finalizando nosso Exemplo\n",
    "\n",
    "Nosso modelo previu um Log-Odds (`z`) de `1.386`. Vamos aplicar a fun√ß√£o Sigmoide para encontrar a probabilidade original.\n",
    "\n",
    "**Matematicamente:**\n",
    "$P = \\frac{1}{1 + e^{-1.386}} = \\frac{1}{1 + 0.25} = \\frac{1}{1.25} = 0.8$\n",
    "\n",
    "Chegamos de volta √† nossa probabilidade inicial de 80%! Isso mostra que o Log-Odds e a Sigmoide s√£o opera√ß√µes inversas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ef7292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O valor de Log-Odds (z) era: 1.3863\n",
      "A probabilidade revertida pela fun√ß√£o Sigmoide √©: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Vamos criar a fun√ß√£o sigmoide em Python\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Revertendo o Log-Odds (z) para a probabilidade original\n",
    "probabilidade_revertida = sigmoid(z)\n",
    "\n",
    "print(f\"O valor de Log-Odds (z) era: {z:.4f}\")\n",
    "print(f\"A probabilidade revertida pela fun√ß√£o Sigmoide √©: {probabilidade_revertida:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d379d0",
   "metadata": {},
   "source": [
    "## Resumo: A F√≥rmula Completa da Regress√£o Log√≠stica\n",
    "\n",
    "Juntando tudo, o modelo de Regress√£o Log√≠stica faz duas coisas:\n",
    "\n",
    "1.  **Calcula o Log-Odds (z)** como uma fun√ß√£o linear das vari√°veis de entrada $ (x_1, x_2, ...) $:\n",
    "    $$z = \\theta_0 + \\theta_1 x_1 + \\dots + \\theta_n x_n$$\n",
    "\n",
    "2.  **Aplica a Fun√ß√£o Sigmoide** em `z` para obter a probabilidade final da classe ser 1 (sucesso):\n",
    "    $$\\hat{y} = P(y=1) = \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "### E como o modelo aprende os coeficientes (Œ∏)?\n",
    "\n",
    "O modelo utiliza um processo de otimiza√ß√£o, como o **Gradiente Descendente**, para encontrar os melhores valores para os coeficientes $ \\theta_0, \\theta_1, \\dots, \\theta_n $. O objetivo √© ajustar esses valores de forma que as probabilidades previstas pelo modelo $ \\hat{y} $ fiquem o mais pr√≥ximo poss√≠vel dos resultados reais (0 ou 1) no conjunto de dados de treino. Mas isso √© um t√≥pico para a nossa pr√≥xima aula!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f4523",
   "metadata": {},
   "source": [
    "## üìå Resumo dos Conceitos\n",
    "\n",
    "| Conceito      | F√≥rmula                               | O que representa?                          |\n",
    "|---------------|----------------------------------------|--------------------------------------------|\n",
    "| Odds (Chance) | $\\frac{P}{1 - P}$                 | A raz√£o entre sucesso e fracasso. |\n",
    "| Log-Odds      | $\\log\\left( \\frac{P}{1 - P} \\right)$ | A escala linear que o modelo usa para trabalhar. |\n",
    "| Sigmoide      | $\\frac{1}{1 + e^{-z}}$                | Converte o Log-Odds de volta em probabilidade. |\n",
    "\n",
    "Espero que esta explica√ß√£o tenha clareado as coisas! A Regress√£o Log√≠stica √© uma ferramenta fant√°stica e entender sua base matem√°tica te dar√° muito mais confian√ßa.\n",
    "\n",
    "**Alguma d√∫vida at√© aqui? Qual t√≥pico voc√™ gostaria de explorar a seguir? Que tal aplicarmos isso a um conjunto de dados real?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
